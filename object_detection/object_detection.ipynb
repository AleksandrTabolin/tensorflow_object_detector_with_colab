{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "object_detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKFRM7KyiR2b",
        "colab_type": "text"
      },
      "source": [
        "Клонируем репозиторий TensorFlow Models:    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cbox8emXldKq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!git clone https://github.com/tensorflow/models.git                                                 "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySUiXGgFio8K",
        "colab_type": "text"
      },
      "source": [
        "Устанавливаем protobuf и компилируем необходимые файлы  в object_detection:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKr21FxlFV8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!apt-get -qq install libprotobuf-java protobuf-compiler                                                \n",
        "%cd ./models/research/\n",
        "!protoc object_detection/protos/*.proto --python_out=.\n",
        "%cd ../.. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oxiYmINti85j",
        "colab_type": "text"
      },
      "source": [
        " Добавляем необходимые пути в переменную окружения PYTHONPATH:\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-tSg17YoPNX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/slim\"\n",
        "os.environ['PYTHONPATH'] += \":/content/models/research/object_detection\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PSLOrFvjcWD",
        "colab_type": "text"
      },
      "source": [
        " Для получения файла из Google Drive устанавливаем PyDrive и авторизируемся:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_m8_5K0PjV8_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmsSnYnEjf4G",
        "colab_type": "text"
      },
      "source": [
        " Скачиваем архив (для drive_file_id нужно указать id вашего файла) и разархивируем его:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IM5QXdHA0RV1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "drive_file_id=\"[YOUR_FILE_ID_HERE]\"\n",
        "\n",
        "training_demo_zip = drive.CreateFile({'id': drive_file_id})\n",
        "training_demo_zip.GetContentFile('training_demo.zip')\n",
        "\n",
        "!unzip training_demo.zip\n",
        "!rm training_demo.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lFFS-9kRj8OM",
        "colab_type": "text"
      },
      "source": [
        " Запускаем процесс обучение, где:\n",
        " \n",
        " ```\n",
        "--train_dir=./training_demo/training #путь к директории где будут лежать результаты обучение\n",
        "--pipeline_config_path=./training_demo/training/ssdlite_mobilenet_v2_coco.config # путь к конфигу\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A4dD1WAl0wiZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python ./models/research/object_detection/legacy/train.py --logtostderr --train_dir=./training_demo/training --pipeline_config_path=./training_demo/training/ssdlite_mobilenet_v2_coco.config"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSiDI3NVlECN",
        "colab_type": "text"
      },
      "source": [
        "Конвертируем результат обучения в модель, которую можно использовать\n",
        " \n",
        "```\n",
        "--pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config  # путь к конфигу\n",
        "--trained_checkpoint_prefix /content/training_demo/training/model.ckpt-[CHECKPOINT_NUMBER] # путь к чекпоинту, который мы хотим конвертировать.\n",
        "--output_directory /content/training_demo/training/output_inference_graph_v1.pb\n",
        "имя конвертированной модели\n",
        "```\n",
        " \n",
        "Номер чекпоинта [CHECKPOINT_NUMBER], можно посмотреть в папке content/training_demo/training/. **ПОСЛЕ** обучения там должны появиться файлы типа model.ckpt-1440.index, model.ckpt-1440.meta. 1440 - [CHECKPOINT_NUMBER].\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss3j0XSPaAIl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python /content/models/research/object_detection/export_inference_graph.py --input_type image_tensor --pipeline_config_path /content/training_demo/training/ssdlite_mobilenet_v2_coco.config --trained_checkpoint_prefix /content/training_demo/training/model.ckpt-[CHECKPOINT_NUMBER] --output_directory /content/training_demo/training/output_inference_graph_v1.pb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvDJjYfemn5l",
        "colab_type": "text"
      },
      "source": [
        "Импортируем зависимости для визулаизации работы обученной модели\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXp0R1HvU5NK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%cd /content/models/research\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from utils import label_map_util\n",
        "from utils import visualization_utils as vis_util"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SH-z_SNLm-_L",
        "colab_type": "text"
      },
      "source": [
        "Визулаизируем работу обученной модели. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Yizund9UlBk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "PATH_TO_MODEL = \"/content/training_demo/training/output_inference_graph_v1.pb/frozen_inference_graph.pb\"\n",
        "PATH_TO_LABELS = \"/content/training_demo/annotations/label_map.pbtxt\"\n",
        "\n",
        "PATH_TO_IMAGE = \"/content/training_demo/images/test/5.jpg\"\n",
        "\n",
        "NUM_CLASSES = 6\n",
        "\n",
        "# Load a model\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "    od_graph_def = tf.GraphDef()\n",
        "    with tf.gfile.GFile(PATH_TO_MODEL, 'rb') as fid:\n",
        "        serialized_graph = fid.read()\n",
        "        od_graph_def.ParseFromString(serialized_graph)\n",
        "        tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "# Load labels\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(\n",
        "    label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "# Detection\n",
        "with detection_graph.as_default():\n",
        "    with tf.Session(graph=detection_graph) as sess:\n",
        "\n",
        "      image = Image.open(PATH_TO_IMAGE)\n",
        "      \n",
        "      # Convert image to numpy array\n",
        "      (im_width, im_height) = image.size    \n",
        "      image_np = np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)      \n",
        "    \n",
        "      image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "      \n",
        "      # Extract image tensor\n",
        "      image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "      \n",
        "      # Extract detection boxes\n",
        "      boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "      \n",
        "      # Extract detection scores\n",
        "      scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "      \n",
        "      # Extract detection classes\n",
        "      classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "      \n",
        "      # Extract number of detectionsd\n",
        "      num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "      \n",
        "      # Actual detection.\n",
        "      (boxes, scores, classes, num_detections) = sess.run(\n",
        "          [boxes, scores, classes, num_detections],\n",
        "          feed_dict={image_tensor: image_np_expanded})\n",
        "     \n",
        "      # Visualization of the results of a detection.\n",
        "      vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "          image_np,\n",
        "          np.squeeze(boxes),\n",
        "          np.squeeze(classes).astype(np.int32),\n",
        "          np.squeeze(scores),\n",
        "          category_index,\n",
        "          use_normalized_coordinates=True,\n",
        "          line_thickness=4,\n",
        "          min_score_thresh = 0.4\n",
        "          )\n",
        "     \n",
        "      IMAGE_SIZE = (18, 12)\n",
        "      plt.figure(figsize=IMAGE_SIZE)\n",
        "      plt.imshow(image_np)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4neVqnrynWNf",
        "colab_type": "text"
      },
      "source": [
        "Архивируем папку с результатами обучения и заливаем её в Google Drive:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U1WTUTr_3eP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!zip -r ./training_demo/training.zip ./training_demo/training/\n",
        "\n",
        "file1 = drive.CreateFile({'title': 'training_result.zip'})\n",
        "file1.SetContentFile('training_demo/training.zip')\n",
        "file1.Upload()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}